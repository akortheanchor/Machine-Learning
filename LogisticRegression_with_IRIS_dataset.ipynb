{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LogisticRegression with IRIS dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akortheanchor/Seaborn/blob/master/LogisticRegression_with_IRIS_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqOosXA8JeFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5hDUpxeJqq2",
        "colab_type": "code",
        "outputId": "103f9225-7e98-4ba9-f1af-d921f865e7bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "iris = load_iris()\n",
        "X_iris = iris.data\n",
        "y_iris = iris.target\n",
        "\n",
        "#Check the shape of data\n",
        "print (X_iris.shape)\n",
        "print (y_iris.shape)\n",
        "\n",
        "#Check if sets balanced\n",
        "print ('Test  1: {}, 2: {}, 3: {}'.format(np.sum(y_iris == 0), np.sum(y_iris == 1), np.sum(y_iris == 2) ) )\n",
        "print ('Train 1: {}, 2: {}, 3: {}'.format(np.sum(y_iris == 0), np.sum(y_iris == 1), np.sum(y_iris == 2) ) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 4)\n",
            "(150,)\n",
            "Test  1: 50, 2: 50, 3: 50\n",
            "Train 1: 50, 2: 50, 3: 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZneY85pJut2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create separate each feature array\n",
        "a = X_iris[:,0]\n",
        "b = X_iris[:,1]\n",
        "c = X_iris[:,2]\n",
        "d = X_iris[:,3]\n",
        "\n",
        "\n",
        "#Scale X data\n",
        "scaler = StandardScaler()\n",
        "scaler.fit_transform (X_iris,y_iris)\n",
        "X_scaled = scaler.transform (X_iris)\n",
        "\n",
        "\n",
        "#Make modified features sets with squares of each feature\n",
        "X_squares   =  np.vstack (([a**2], [b**2], [c **2], [d**2])).T\n",
        "\n",
        "#Make modified features set with multiplied pairs of each feature\n",
        "X_multi = np.vstack ((a*b, a*c, a*d, b*c, b*d, c*d)).T\n",
        "\n",
        "#Make polynomial transformation n = 10\n",
        "transform = PolynomialFeatures(10)\n",
        "transform.fit_transform(X_iris)\n",
        "X_poly = transform.transform(X_iris)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2oNyRVwJxo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Make split for original data\n",
        "(X_tr_o, X_ts_o, y_tr_o, y_ts_o ) = train_test_split(X_iris, y_iris, stratify=y_iris, test_size= 0.3)\n",
        "\n",
        "#Make split for scaled data\n",
        "(X_tr_sc, X_ts_sc, y_tr_sc, y_ts_sc) = train_test_split(X_scaled, y_iris, stratify = y_iris, test_size = 0.30)\n",
        "\n",
        "#Make split of polynomial extended features set\n",
        "(X_tr_p, X_ts_p, y_tr_p, y_ts_p ) = train_test_split(X_poly, y_iris, stratify=y_iris, test_size= 0.3)\n",
        "\n",
        "#Make split of squares of each feature\n",
        "(X_tr_sq, X_ts_sq, y_tr_sq, y_ts_sq ) = train_test_split(X_squares, y_iris, stratify = y_iris, test_size = 0.3)\n",
        "\n",
        "#Make split of  multyplied pairs of each feature\n",
        "(X_tr_m, X_ts_m, y_tr_m, y_ts_m ) = train_test_split(X_multi, y_iris, stratify = y_iris, test_size = 0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7Luc57CKaqH",
        "colab_type": "code",
        "outputId": "e4d8c42b-201f-4686-b003-e8264077d2d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print ('Accuracy score for original: {}'.format(  z_o) )\n",
        "print ('Accuracy score for scaled: {}'.format (  z_sc) )\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score for original: 0.9555555555555556\n",
            "Accuracy score for scaled: 0.9777777777777777\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}